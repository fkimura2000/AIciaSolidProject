{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 4109335025144217603\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5750390784\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 50685855360561411\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:0b:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 750x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_row = 2\n",
    "num_col = 5\n",
    "\n",
    "# plot images\n",
    "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "for i in range(10):\n",
    "    ax = axes[i//num_col, i%num_col]\n",
    "    ax.imshow(x_train[i], cmap='gray')\n",
    "    ax.set_title('Label: {}'.format(y_train[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(28, 28))  # shape of input\n",
    "z = Flatten()(x)  # 28x28 -> 784\n",
    "z = Dense(units=128, activation='relu')(z)  # dense + ReLU\n",
    "p = Dense(units=10, activation='softmax')(z)  # dense + softmax\n",
    "\n",
    "model = Model(\n",
    "    inputs=x,\n",
    "    outputs=p,\n",
    ")  # build DNN model\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])  # compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=3),\n",
    "    ModelCheckpoint(filepath=os.path.join('models', 'DNN', 'test.h5'), save_best_only=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 3s 4ms/step - loss: 5.5885 - acc: 0.8596 - val_loss: 1.5793 - val_acc: 0.9168\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0371 - acc: 0.9191 - val_loss: 0.8538 - val_acc: 0.9160\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5035 - acc: 0.9367 - val_loss: 0.6752 - val_acc: 0.9291\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3148 - acc: 0.9491 - val_loss: 0.5418 - val_acc: 0.9339\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2273 - acc: 0.9571 - val_loss: 0.4978 - val_acc: 0.9366\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1744 - acc: 0.9642 - val_loss: 0.4659 - val_acc: 0.9405\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1504 - acc: 0.9671 - val_loss: 0.4547 - val_acc: 0.9420\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1428 - acc: 0.9680 - val_loss: 0.4249 - val_acc: 0.9498\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1230 - acc: 0.9716 - val_loss: 0.3814 - val_acc: 0.9482\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1338 - acc: 0.9693 - val_loss: 0.3818 - val_acc: 0.9481\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1191 - acc: 0.9716 - val_loss: 0.3586 - val_acc: 0.9509\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1102 - acc: 0.9742 - val_loss: 0.3621 - val_acc: 0.9518\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0996 - acc: 0.9758 - val_loss: 0.3999 - val_acc: 0.9493\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1111 - acc: 0.9744 - val_loss: 0.3702 - val_acc: 0.9532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2472a848400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "model.fit(x=x_train, y=y_train, batch_size=128, epochs=100, callbacks=callbacks, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9563"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see accuracy\n",
    "\n",
    "accuracy_score(y_test, model.predict(x_test).argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this model is 95.66% (in the author's environment.) Pretty good!\n",
    "\n",
    "このモデルの精度は（筆者の環境では） 95.66% です。\n",
    "悪くない！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class DenseModel:\n",
    "    def __init__(self, layers=1, hid_dim=128):\n",
    "        self.input = Input(shape=(28, 28), name='input')\n",
    "        self.flatten = Flatten(name='flatten')\n",
    "        self.denses = OrderedDict()\n",
    "        for i in range(layers):\n",
    "            name = 'dense_{}'.format(i)\n",
    "            self.denses[name] = Dense(units=hid_dim, activation='relu', name=name)\n",
    "        self.last = Dense(units=10, activation='softmax', name='last')\n",
    "    \n",
    "    \n",
    "    def build(self):\n",
    "        x = self.input\n",
    "        z = self.flatten(x)\n",
    "        for dense in self.denses.values():\n",
    "            z = dense(z)\n",
    "        p = self.last(z)\n",
    "        \n",
    "        model = Model(inputs=x, outputs=p)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== layers: 1 ; hid_dim: 1 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.9207 - acc: 0.1117 - val_loss: 2.3032 - val_acc: 0.1058\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3020 - acc: 0.1138 - val_loss: 2.3022 - val_acc: 0.1059\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3012 - acc: 0.1139 - val_loss: 2.3022 - val_acc: 0.1060\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1139 - val_loss: 2.3021 - val_acc: 0.1060\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1139 - val_loss: 2.3021 - val_acc: 0.1060\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3021 - val_acc: 0.1060\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3010 - acc: 0.1140 - val_loss: 2.3020 - val_acc: 0.1060\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3021 - val_acc: 0.1060\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3021 - val_acc: 0.1060\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3021 - val_acc: 0.1060\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 1 ; hid_dim: 2 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 2.7105 - acc: 0.1103 - val_loss: 2.3110 - val_acc: 0.1060\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3015 - acc: 0.1140 - val_loss: 2.3083 - val_acc: 0.1060\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3007 - acc: 0.1140 - val_loss: 2.3082 - val_acc: 0.1060\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2245 - acc: 0.1405 - val_loss: 2.1353 - val_acc: 0.1868\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.1029 - acc: 0.1928 - val_loss: 2.0782 - val_acc: 0.2024\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0549 - acc: 0.2027 - val_loss: 2.0625 - val_acc: 0.2013\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0319 - acc: 0.2066 - val_loss: 2.0577 - val_acc: 0.2059\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0187 - acc: 0.2069 - val_loss: 2.0454 - val_acc: 0.2077\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0094 - acc: 0.2093 - val_loss: 2.0393 - val_acc: 0.2075\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0017 - acc: 0.2099 - val_loss: 2.0285 - val_acc: 0.2078\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9945 - acc: 0.2118 - val_loss: 2.0274 - val_acc: 0.2099\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9874 - acc: 0.2123 - val_loss: 2.0197 - val_acc: 0.2094\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9852 - acc: 0.2125 - val_loss: 2.0198 - val_acc: 0.2119\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9839 - acc: 0.2133 - val_loss: 2.0094 - val_acc: 0.2155\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9780 - acc: 0.2147 - val_loss: 2.0146 - val_acc: 0.2143\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9772 - acc: 0.2174 - val_loss: 2.0007 - val_acc: 0.2181\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9714 - acc: 0.2193 - val_loss: 1.9924 - val_acc: 0.2172\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.9614 - acc: 0.2249 - val_loss: 1.9749 - val_acc: 0.2309\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9492 - acc: 0.2314 - val_loss: 1.9514 - val_acc: 0.2437\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9316 - acc: 0.2374 - val_loss: 1.9246 - val_acc: 0.2547\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9141 - acc: 0.2477 - val_loss: 1.9094 - val_acc: 0.2632\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.8872 - acc: 0.2627 - val_loss: 1.8876 - val_acc: 0.2747\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.8320 - acc: 0.2699 - val_loss: 1.8047 - val_acc: 0.2717\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7777 - acc: 0.2800 - val_loss: 1.7641 - val_acc: 0.2751\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7530 - acc: 0.2793 - val_loss: 1.7485 - val_acc: 0.2814\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7409 - acc: 0.2866 - val_loss: 1.7539 - val_acc: 0.2745\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7332 - acc: 0.2858 - val_loss: 1.7305 - val_acc: 0.2819\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7289 - acc: 0.2906 - val_loss: 1.7333 - val_acc: 0.2780\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7210 - acc: 0.2974 - val_loss: 1.7365 - val_acc: 0.2863\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7142 - acc: 0.2993 - val_loss: 1.7171 - val_acc: 0.2922\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7059 - acc: 0.3063 - val_loss: 1.7065 - val_acc: 0.2995\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7013 - acc: 0.3022 - val_loss: 1.7195 - val_acc: 0.2865\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6981 - acc: 0.3048 - val_loss: 1.6989 - val_acc: 0.3061\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.6940 - acc: 0.3071 - val_loss: 1.7018 - val_acc: 0.3052\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6921 - acc: 0.3041 - val_loss: 1.6994 - val_acc: 0.3062\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6924 - acc: 0.3040 - val_loss: 1.6915 - val_acc: 0.3118\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6898 - acc: 0.3078 - val_loss: 1.7027 - val_acc: 0.3159\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6864 - acc: 0.3098 - val_loss: 1.6926 - val_acc: 0.2901\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6865 - acc: 0.3052 - val_loss: 1.6866 - val_acc: 0.3144\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6874 - acc: 0.3079 - val_loss: 1.7197 - val_acc: 0.2949\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6852 - acc: 0.3099 - val_loss: 1.6979 - val_acc: 0.2983\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6836 - acc: 0.3099 - val_loss: 1.6953 - val_acc: 0.3063\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 1 ; hid_dim: 4 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.7741 - acc: 0.1123 - val_loss: 2.3047 - val_acc: 0.1060\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3029 - acc: 0.1140 - val_loss: 2.3026 - val_acc: 0.1060\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3018 - acc: 0.1140 - val_loss: 2.3025 - val_acc: 0.1060\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3013 - acc: 0.1140 - val_loss: 2.3025 - val_acc: 0.1060\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3024 - val_acc: 0.1060\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3010 - acc: 0.1140 - val_loss: 2.3023 - val_acc: 0.1060\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3010 - acc: 0.1140 - val_loss: 2.3022 - val_acc: 0.1060\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3010 - acc: 0.1140 - val_loss: 2.3023 - val_acc: 0.1060\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3010 - acc: 0.1140 - val_loss: 2.3022 - val_acc: 0.1060\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3010 - acc: 0.1140 - val_loss: 2.3022 - val_acc: 0.1060\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 1 ; hid_dim: 8 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.6078 - acc: 0.1256 - val_loss: 2.1824 - val_acc: 0.1689\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.1164 - acc: 0.2002 - val_loss: 1.9942 - val_acc: 0.2470\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9648 - acc: 0.2624 - val_loss: 1.8775 - val_acc: 0.2903\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.8488 - acc: 0.3027 - val_loss: 1.8011 - val_acc: 0.3477\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5914 - acc: 0.3971 - val_loss: 1.5121 - val_acc: 0.4184\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.4418 - acc: 0.4346 - val_loss: 1.4231 - val_acc: 0.4518\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3632 - acc: 0.4554 - val_loss: 1.3615 - val_acc: 0.4511\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3076 - acc: 0.4703 - val_loss: 1.2964 - val_acc: 0.4899\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2639 - acc: 0.4856 - val_loss: 1.2547 - val_acc: 0.5095\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2239 - acc: 0.5009 - val_loss: 1.2820 - val_acc: 0.5337\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1949 - acc: 0.5127 - val_loss: 1.1894 - val_acc: 0.5222\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1575 - acc: 0.5256 - val_loss: 1.1826 - val_acc: 0.5407\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1316 - acc: 0.5344 - val_loss: 1.1402 - val_acc: 0.5329\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0960 - acc: 0.5546 - val_loss: 1.0969 - val_acc: 0.5622\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0487 - acc: 0.5822 - val_loss: 1.0774 - val_acc: 0.6140\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0191 - acc: 0.6019 - val_loss: 1.0225 - val_acc: 0.6056\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9847 - acc: 0.6118 - val_loss: 0.9873 - val_acc: 0.6198\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9565 - acc: 0.6312 - val_loss: 0.9767 - val_acc: 0.6191\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9159 - acc: 0.6484 - val_loss: 0.9097 - val_acc: 0.6534\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8592 - acc: 0.6743 - val_loss: 0.8497 - val_acc: 0.6852\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7907 - acc: 0.7163 - val_loss: 0.7724 - val_acc: 0.7398\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7135 - acc: 0.7551 - val_loss: 0.7171 - val_acc: 0.7728\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6696 - acc: 0.7803 - val_loss: 0.6757 - val_acc: 0.7933\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6531 - acc: 0.7917 - val_loss: 0.6812 - val_acc: 0.8031\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6329 - acc: 0.8062 - val_loss: 0.6434 - val_acc: 0.8082\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6147 - acc: 0.8151 - val_loss: 0.6376 - val_acc: 0.8152\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6020 - acc: 0.8197 - val_loss: 0.6288 - val_acc: 0.8146\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5943 - acc: 0.8206 - val_loss: 0.6131 - val_acc: 0.8180\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5842 - acc: 0.8245 - val_loss: 0.5979 - val_acc: 0.8207\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5798 - acc: 0.8274 - val_loss: 0.6031 - val_acc: 0.8137\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5682 - acc: 0.8292 - val_loss: 0.6018 - val_acc: 0.8175\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5619 - acc: 0.8307 - val_loss: 0.5647 - val_acc: 0.8333\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5545 - acc: 0.8334 - val_loss: 0.5685 - val_acc: 0.8325\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5451 - acc: 0.8369 - val_loss: 0.5486 - val_acc: 0.8437\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5380 - acc: 0.8395 - val_loss: 0.5447 - val_acc: 0.8403\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5309 - acc: 0.8431 - val_loss: 0.5502 - val_acc: 0.8342\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5257 - acc: 0.8437 - val_loss: 0.5366 - val_acc: 0.8417\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5203 - acc: 0.8458 - val_loss: 0.5508 - val_acc: 0.8372\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5178 - acc: 0.8470 - val_loss: 0.5392 - val_acc: 0.8388\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5211 - acc: 0.8454 - val_loss: 0.5229 - val_acc: 0.8463\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5086 - acc: 0.8487 - val_loss: 0.5302 - val_acc: 0.8391\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5064 - acc: 0.8496 - val_loss: 0.5368 - val_acc: 0.8463\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5079 - acc: 0.8500 - val_loss: 0.5368 - val_acc: 0.8470\n",
      "313/313 [==============================] - 0s 996us/step\n",
      "======== layers: 1 ; hid_dim: 16 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 3.2821 - acc: 0.1360 - val_loss: 2.1657 - val_acc: 0.1922\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.1163 - acc: 0.1919 - val_loss: 2.0865 - val_acc: 0.2014\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0633 - acc: 0.2023 - val_loss: 2.0621 - val_acc: 0.2084\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9081 - acc: 0.2739 - val_loss: 1.7911 - val_acc: 0.3117\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6809 - acc: 0.3457 - val_loss: 1.5606 - val_acc: 0.4005\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3984 - acc: 0.4635 - val_loss: 1.2699 - val_acc: 0.5227\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2167 - acc: 0.5367 - val_loss: 1.1619 - val_acc: 0.5730\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1258 - acc: 0.5667 - val_loss: 1.1133 - val_acc: 0.5819\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0745 - acc: 0.5842 - val_loss: 1.0606 - val_acc: 0.5970\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0450 - acc: 0.5956 - val_loss: 1.0390 - val_acc: 0.6089\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0118 - acc: 0.6085 - val_loss: 1.0576 - val_acc: 0.6121\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9846 - acc: 0.6282 - val_loss: 0.9918 - val_acc: 0.6450\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9475 - acc: 0.6490 - val_loss: 0.9597 - val_acc: 0.6503\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8912 - acc: 0.6716 - val_loss: 0.8972 - val_acc: 0.6721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8162 - acc: 0.7068 - val_loss: 0.8125 - val_acc: 0.7152\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7784 - acc: 0.7420 - val_loss: 0.7694 - val_acc: 0.7492\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7321 - acc: 0.7610 - val_loss: 0.7396 - val_acc: 0.7510\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7015 - acc: 0.7690 - val_loss: 0.6880 - val_acc: 0.7811\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6854 - acc: 0.7727 - val_loss: 0.6838 - val_acc: 0.7817\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6693 - acc: 0.7795 - val_loss: 0.6566 - val_acc: 0.7970\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6609 - acc: 0.7830 - val_loss: 0.6531 - val_acc: 0.7951\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6549 - acc: 0.7840 - val_loss: 0.6650 - val_acc: 0.7847\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6504 - acc: 0.7864 - val_loss: 0.6565 - val_acc: 0.7897\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6471 - acc: 0.7876 - val_loss: 0.6712 - val_acc: 0.7788\n",
      "313/313 [==============================] - 0s 988us/step\n",
      "======== layers: 1 ; hid_dim: 32 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 4.0165 - acc: 0.4062 - val_loss: 1.4391 - val_acc: 0.5605\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2157 - acc: 0.6342 - val_loss: 1.0087 - val_acc: 0.7057\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8735 - acc: 0.7779 - val_loss: 0.7884 - val_acc: 0.8240\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6953 - acc: 0.8350 - val_loss: 0.6900 - val_acc: 0.8577\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5839 - acc: 0.8591 - val_loss: 0.5852 - val_acc: 0.8681\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5050 - acc: 0.8752 - val_loss: 0.5722 - val_acc: 0.8786\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4580 - acc: 0.8860 - val_loss: 0.4894 - val_acc: 0.8936\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4103 - acc: 0.8974 - val_loss: 0.4506 - val_acc: 0.8957\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3589 - acc: 0.9093 - val_loss: 0.4126 - val_acc: 0.9125\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3343 - acc: 0.9165 - val_loss: 0.4048 - val_acc: 0.9062\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3043 - acc: 0.9223 - val_loss: 0.3733 - val_acc: 0.9232\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2885 - acc: 0.9266 - val_loss: 0.3487 - val_acc: 0.9240\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2685 - acc: 0.9303 - val_loss: 0.3241 - val_acc: 0.9269\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2519 - acc: 0.9337 - val_loss: 0.3383 - val_acc: 0.9319\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2377 - acc: 0.9373 - val_loss: 0.2980 - val_acc: 0.9320\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2232 - acc: 0.9409 - val_loss: 0.2971 - val_acc: 0.9309\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2228 - acc: 0.9409 - val_loss: 0.2909 - val_acc: 0.9337\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2140 - acc: 0.9431 - val_loss: 0.2723 - val_acc: 0.9368\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2054 - acc: 0.9445 - val_loss: 0.2651 - val_acc: 0.9387\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1981 - acc: 0.9467 - val_loss: 0.2649 - val_acc: 0.9377\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1929 - acc: 0.9464 - val_loss: 0.2697 - val_acc: 0.9389\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1888 - acc: 0.9487 - val_loss: 0.2731 - val_acc: 0.9348\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1857 - acc: 0.9492 - val_loss: 0.2496 - val_acc: 0.9415\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1806 - acc: 0.9510 - val_loss: 0.2490 - val_acc: 0.9402\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1736 - acc: 0.9513 - val_loss: 0.2516 - val_acc: 0.9419\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1752 - acc: 0.9510 - val_loss: 0.2663 - val_acc: 0.9385\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1703 - acc: 0.9529 - val_loss: 0.2572 - val_acc: 0.9404\n",
      "313/313 [==============================] - 0s 983us/step\n",
      "======== layers: 1 ; hid_dim: 64 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.2213 - acc: 0.7942 - val_loss: 1.1386 - val_acc: 0.8177\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8340 - acc: 0.8350 - val_loss: 0.7184 - val_acc: 0.8495\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5572 - acc: 0.8739 - val_loss: 0.5743 - val_acc: 0.8764\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4411 - acc: 0.8922 - val_loss: 0.5373 - val_acc: 0.8981\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3653 - acc: 0.9080 - val_loss: 0.4696 - val_acc: 0.9071\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3083 - acc: 0.9196 - val_loss: 0.4482 - val_acc: 0.9102\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2789 - acc: 0.9265 - val_loss: 0.3798 - val_acc: 0.9245\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2484 - acc: 0.9329 - val_loss: 0.3704 - val_acc: 0.9242\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2271 - acc: 0.9383 - val_loss: 0.3894 - val_acc: 0.9295\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2149 - acc: 0.9413 - val_loss: 0.3520 - val_acc: 0.9321\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2041 - acc: 0.9442 - val_loss: 0.3521 - val_acc: 0.9340\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1919 - acc: 0.9475 - val_loss: 0.3254 - val_acc: 0.9292\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1765 - acc: 0.9508 - val_loss: 0.3060 - val_acc: 0.9373\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1649 - acc: 0.9534 - val_loss: 0.2931 - val_acc: 0.9443\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1579 - acc: 0.9567 - val_loss: 0.2867 - val_acc: 0.9392\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1443 - acc: 0.9604 - val_loss: 0.2695 - val_acc: 0.9445\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1493 - acc: 0.9587 - val_loss: 0.2640 - val_acc: 0.9449\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1368 - acc: 0.9619 - val_loss: 0.2519 - val_acc: 0.9486\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1346 - acc: 0.9623 - val_loss: 0.2558 - val_acc: 0.9447\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1201 - acc: 0.9663 - val_loss: 0.2511 - val_acc: 0.9450\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1150 - acc: 0.9669 - val_loss: 0.3169 - val_acc: 0.9463\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1055 - acc: 0.9697 - val_loss: 0.2500 - val_acc: 0.9522\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1119 - acc: 0.9692 - val_loss: 0.2570 - val_acc: 0.9459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1069 - acc: 0.9693 - val_loss: 0.2487 - val_acc: 0.9511\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1105 - acc: 0.9688 - val_loss: 0.2541 - val_acc: 0.9472\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1009 - acc: 0.9720 - val_loss: 0.2590 - val_acc: 0.9517\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0969 - acc: 0.9724 - val_loss: 0.2473 - val_acc: 0.9553\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0907 - acc: 0.9749 - val_loss: 0.2697 - val_acc: 0.9513\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0881 - acc: 0.9750 - val_loss: 0.2696 - val_acc: 0.9517\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0900 - acc: 0.9745 - val_loss: 0.2795 - val_acc: 0.9531\n",
      "313/313 [==============================] - 0s 988us/step\n",
      "======== layers: 1 ; hid_dim: 128 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.3024 - acc: 0.8669 - val_loss: 1.4038 - val_acc: 0.9149\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9293 - acc: 0.9220 - val_loss: 0.7951 - val_acc: 0.9232\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4664 - acc: 0.9339 - val_loss: 0.5596 - val_acc: 0.9238\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3061 - acc: 0.9444 - val_loss: 0.4852 - val_acc: 0.9357\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2251 - acc: 0.9535 - val_loss: 0.4554 - val_acc: 0.9389\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1719 - acc: 0.9602 - val_loss: 0.4302 - val_acc: 0.9415\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1587 - acc: 0.9631 - val_loss: 0.4055 - val_acc: 0.9395\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1467 - acc: 0.9660 - val_loss: 0.4070 - val_acc: 0.9407\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1474 - acc: 0.9655 - val_loss: 0.3443 - val_acc: 0.9472\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1334 - acc: 0.9690 - val_loss: 0.3398 - val_acc: 0.9502\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1289 - acc: 0.9702 - val_loss: 0.3761 - val_acc: 0.9499\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1210 - acc: 0.9702 - val_loss: 0.3559 - val_acc: 0.9510\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1037 - acc: 0.9747 - val_loss: 0.3504 - val_acc: 0.9487\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 1 ; hid_dim: 256 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 5.4364 - acc: 0.8850 - val_loss: 1.3957 - val_acc: 0.9287\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8601 - acc: 0.9434 - val_loss: 0.8817 - val_acc: 0.9370\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4372 - acc: 0.9599 - val_loss: 0.6884 - val_acc: 0.9433\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2727 - acc: 0.9691 - val_loss: 0.5764 - val_acc: 0.9519\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1996 - acc: 0.9749 - val_loss: 0.5449 - val_acc: 0.9519\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1578 - acc: 0.9756 - val_loss: 0.5498 - val_acc: 0.9578\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1841 - acc: 0.9755 - val_loss: 0.5250 - val_acc: 0.9578\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1510 - acc: 0.9769 - val_loss: 0.5488 - val_acc: 0.9548\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1393 - acc: 0.9778 - val_loss: 0.4396 - val_acc: 0.9579\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1383 - acc: 0.9782 - val_loss: 0.5117 - val_acc: 0.9587\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1079 - acc: 0.9825 - val_loss: 0.4874 - val_acc: 0.9622\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1462 - acc: 0.9784 - val_loss: 0.5939 - val_acc: 0.9523\n",
      "313/313 [==============================] - 0s 897us/step\n",
      "======== layers: 1 ; hid_dim: 512 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.7285 - acc: 0.8976 - val_loss: 1.5056 - val_acc: 0.9289\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7278 - acc: 0.9535 - val_loss: 0.8162 - val_acc: 0.9417\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3467 - acc: 0.9671 - val_loss: 0.6466 - val_acc: 0.9565\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2251 - acc: 0.9752 - val_loss: 0.6790 - val_acc: 0.9528\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2144 - acc: 0.9759 - val_loss: 0.6643 - val_acc: 0.9580\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1993 - acc: 0.9778 - val_loss: 0.6133 - val_acc: 0.9561\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1880 - acc: 0.9785 - val_loss: 0.6665 - val_acc: 0.9588\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2133 - acc: 0.9773 - val_loss: 0.5818 - val_acc: 0.9622\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1921 - acc: 0.9800 - val_loss: 0.6146 - val_acc: 0.9600\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1803 - acc: 0.9817 - val_loss: 0.6073 - val_acc: 0.9632\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1752 - acc: 0.9807 - val_loss: 0.6387 - val_acc: 0.9607\n",
      "313/313 [==============================] - 0s 882us/step\n",
      "======== layers: 1 ; hid_dim: 1024 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.6194 - acc: 0.9085 - val_loss: 0.9700 - val_acc: 0.9473\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5292 - acc: 0.9595 - val_loss: 0.5397 - val_acc: 0.9598\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2542 - acc: 0.9725 - val_loss: 0.6638 - val_acc: 0.9498\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2431 - acc: 0.9736 - val_loss: 0.7086 - val_acc: 0.9517\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1931 - acc: 0.9772 - val_loss: 0.5258 - val_acc: 0.9613\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1456 - acc: 0.9809 - val_loss: 0.6243 - val_acc: 0.9548\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1790 - acc: 0.9800 - val_loss: 0.6580 - val_acc: 0.9561\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2521 - acc: 0.9752 - val_loss: 0.5248 - val_acc: 0.9619\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1858 - acc: 0.9793 - val_loss: 0.7064 - val_acc: 0.9603\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2009 - acc: 0.9792 - val_loss: 0.6981 - val_acc: 0.9583\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2319 - acc: 0.9788 - val_loss: 0.6686 - val_acc: 0.9604\n",
      "313/313 [==============================] - 0s 914us/step\n",
      "======== layers: 2 ; hid_dim: 1 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3016 - acc: 0.1120 - val_loss: 2.3019 - val_acc: 0.1060\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3020 - val_acc: 0.1060\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3021 - val_acc: 0.1060\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3021 - val_acc: 0.1060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1000us/step\n",
      "======== layers: 2 ; hid_dim: 2 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 2.3036 - acc: 0.1134 - val_loss: 2.3019 - val_acc: 0.1060\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3020 - val_acc: 0.1060\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3010 - acc: 0.1140 - val_loss: 2.3020 - val_acc: 0.1060\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3022 - val_acc: 0.1060\n",
      "313/313 [==============================] - 0s 994us/step\n",
      "======== layers: 2 ; hid_dim: 4 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 2.4157 - acc: 0.1469 - val_loss: 2.0473 - val_acc: 0.1961\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0148 - acc: 0.2035 - val_loss: 1.9812 - val_acc: 0.2028\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9671 - acc: 0.2103 - val_loss: 1.9514 - val_acc: 0.2106\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9369 - acc: 0.2162 - val_loss: 1.9183 - val_acc: 0.2274\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.8675 - acc: 0.2565 - val_loss: 1.8245 - val_acc: 0.2717\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.8154 - acc: 0.2622 - val_loss: 1.7955 - val_acc: 0.2697\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7964 - acc: 0.2649 - val_loss: 1.7815 - val_acc: 0.2460\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7835 - acc: 0.2676 - val_loss: 1.7692 - val_acc: 0.2790\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7745 - acc: 0.2704 - val_loss: 1.7637 - val_acc: 0.2718\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7679 - acc: 0.2735 - val_loss: 1.7544 - val_acc: 0.2689\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7620 - acc: 0.2770 - val_loss: 1.7512 - val_acc: 0.2748\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7567 - acc: 0.2794 - val_loss: 1.7469 - val_acc: 0.2784\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7521 - acc: 0.2836 - val_loss: 1.7477 - val_acc: 0.2807\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7499 - acc: 0.2852 - val_loss: 1.7379 - val_acc: 0.2877\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7462 - acc: 0.2868 - val_loss: 1.7336 - val_acc: 0.2881\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7436 - acc: 0.2891 - val_loss: 1.7326 - val_acc: 0.2863\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7407 - acc: 0.2908 - val_loss: 1.7374 - val_acc: 0.2850\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7395 - acc: 0.2919 - val_loss: 1.7307 - val_acc: 0.2902\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7370 - acc: 0.2941 - val_loss: 1.7270 - val_acc: 0.2889\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7351 - acc: 0.2958 - val_loss: 1.7268 - val_acc: 0.2970\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7338 - acc: 0.2982 - val_loss: 1.7354 - val_acc: 0.2963\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7307 - acc: 0.2995 - val_loss: 1.7202 - val_acc: 0.2895\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7272 - acc: 0.3050 - val_loss: 1.7170 - val_acc: 0.2964\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7201 - acc: 0.3081 - val_loss: 1.7041 - val_acc: 0.3080\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7119 - acc: 0.3075 - val_loss: 1.6955 - val_acc: 0.3108\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7049 - acc: 0.3088 - val_loss: 1.6898 - val_acc: 0.3110\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7002 - acc: 0.3073 - val_loss: 1.6902 - val_acc: 0.3124\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6954 - acc: 0.3095 - val_loss: 1.6940 - val_acc: 0.3041\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6938 - acc: 0.3074 - val_loss: 1.6803 - val_acc: 0.3114\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6893 - acc: 0.3069 - val_loss: 1.6766 - val_acc: 0.3064\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6866 - acc: 0.3075 - val_loss: 1.6831 - val_acc: 0.3106\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6842 - acc: 0.3055 - val_loss: 1.6706 - val_acc: 0.3033\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6822 - acc: 0.3046 - val_loss: 1.6690 - val_acc: 0.3023\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6794 - acc: 0.3039 - val_loss: 1.6677 - val_acc: 0.3042\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6778 - acc: 0.3022 - val_loss: 1.6655 - val_acc: 0.3027\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6776 - acc: 0.2992 - val_loss: 1.6633 - val_acc: 0.2943\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6748 - acc: 0.3003 - val_loss: 1.6648 - val_acc: 0.2966\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6756 - acc: 0.2993 - val_loss: 1.6666 - val_acc: 0.2942\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6729 - acc: 0.3018 - val_loss: 1.6589 - val_acc: 0.3068\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6715 - acc: 0.3090 - val_loss: 1.6569 - val_acc: 0.3122\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6734 - acc: 0.3094 - val_loss: 1.6557 - val_acc: 0.3111\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6705 - acc: 0.3109 - val_loss: 1.6878 - val_acc: 0.2940\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6700 - acc: 0.3133 - val_loss: 1.6546 - val_acc: 0.3096\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6690 - acc: 0.3176 - val_loss: 1.6535 - val_acc: 0.3176\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6668 - acc: 0.3217 - val_loss: 1.6516 - val_acc: 0.3239\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6626 - acc: 0.3286 - val_loss: 1.6431 - val_acc: 0.3425\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6551 - acc: 0.3403 - val_loss: 1.6352 - val_acc: 0.3388\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6436 - acc: 0.3426 - val_loss: 1.6304 - val_acc: 0.3388\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6388 - acc: 0.3417 - val_loss: 1.6248 - val_acc: 0.3419\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6353 - acc: 0.3390 - val_loss: 1.6242 - val_acc: 0.3368\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6346 - acc: 0.3376 - val_loss: 1.6277 - val_acc: 0.3275\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6306 - acc: 0.3395 - val_loss: 1.6213 - val_acc: 0.3390\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6307 - acc: 0.3348 - val_loss: 1.6226 - val_acc: 0.3275\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6295 - acc: 0.3357 - val_loss: 1.6188 - val_acc: 0.3253\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6289 - acc: 0.3334 - val_loss: 1.6168 - val_acc: 0.3252\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6270 - acc: 0.3311 - val_loss: 1.6160 - val_acc: 0.3296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6251 - acc: 0.3336 - val_loss: 1.6220 - val_acc: 0.3232\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6255 - acc: 0.3316 - val_loss: 1.6142 - val_acc: 0.3183\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6246 - acc: 0.3316 - val_loss: 1.6127 - val_acc: 0.3249\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6233 - acc: 0.3311 - val_loss: 1.6173 - val_acc: 0.3184\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6220 - acc: 0.3305 - val_loss: 1.6126 - val_acc: 0.3267\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6215 - acc: 0.3286 - val_loss: 1.6269 - val_acc: 0.3144\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6215 - acc: 0.3274 - val_loss: 1.6092 - val_acc: 0.3268\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6207 - acc: 0.3272 - val_loss: 1.6090 - val_acc: 0.3306\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6190 - acc: 0.3240 - val_loss: 1.6071 - val_acc: 0.3232\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6181 - acc: 0.3248 - val_loss: 1.6051 - val_acc: 0.3248\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6175 - acc: 0.3221 - val_loss: 1.6061 - val_acc: 0.3237\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6157 - acc: 0.3213 - val_loss: 1.6117 - val_acc: 0.3093\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6138 - acc: 0.3198 - val_loss: 1.6032 - val_acc: 0.3171\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6117 - acc: 0.3188 - val_loss: 1.6006 - val_acc: 0.3163\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6104 - acc: 0.3141 - val_loss: 1.6040 - val_acc: 0.3026\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6093 - acc: 0.3115 - val_loss: 1.5978 - val_acc: 0.3042\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6072 - acc: 0.3111 - val_loss: 1.6028 - val_acc: 0.2942\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6054 - acc: 0.3103 - val_loss: 1.5952 - val_acc: 0.3032\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6011 - acc: 0.3141 - val_loss: 1.5883 - val_acc: 0.3149\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5981 - acc: 0.3204 - val_loss: 1.5838 - val_acc: 0.3116\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5962 - acc: 0.3267 - val_loss: 1.5796 - val_acc: 0.3454\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5914 - acc: 0.3339 - val_loss: 1.5764 - val_acc: 0.3461\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5886 - acc: 0.3416 - val_loss: 1.5750 - val_acc: 0.3443\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5869 - acc: 0.3457 - val_loss: 1.5689 - val_acc: 0.3516\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5846 - acc: 0.3505 - val_loss: 1.5680 - val_acc: 0.3568\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5823 - acc: 0.3536 - val_loss: 1.5641 - val_acc: 0.3554\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5803 - acc: 0.3583 - val_loss: 1.5718 - val_acc: 0.3578\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5801 - acc: 0.3601 - val_loss: 1.5659 - val_acc: 0.3512\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5786 - acc: 0.3635 - val_loss: 1.5915 - val_acc: 0.3432\n",
      "313/313 [==============================] - 0s 1000us/step\n",
      "======== layers: 2 ; hid_dim: 8 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 3.8906 - acc: 0.1105 - val_loss: 2.3032 - val_acc: 0.1070\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2262 - acc: 0.1562 - val_loss: 2.0758 - val_acc: 0.2209\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9523 - acc: 0.2822 - val_loss: 1.7810 - val_acc: 0.3335\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7127 - acc: 0.3624 - val_loss: 1.6487 - val_acc: 0.4123\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5573 - acc: 0.4135 - val_loss: 1.5020 - val_acc: 0.4345\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3863 - acc: 0.4810 - val_loss: 1.2840 - val_acc: 0.5165\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2425 - acc: 0.5332 - val_loss: 1.2211 - val_acc: 0.5387\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1750 - acc: 0.5446 - val_loss: 1.1742 - val_acc: 0.5498\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1352 - acc: 0.5554 - val_loss: 1.1079 - val_acc: 0.5762\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0939 - acc: 0.5755 - val_loss: 1.0778 - val_acc: 0.5723\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0703 - acc: 0.5825 - val_loss: 1.0603 - val_acc: 0.5863\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0542 - acc: 0.5866 - val_loss: 1.0490 - val_acc: 0.5880\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0378 - acc: 0.5935 - val_loss: 1.0320 - val_acc: 0.5952\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0276 - acc: 0.5965 - val_loss: 1.0205 - val_acc: 0.5961\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0262 - acc: 0.5996 - val_loss: 1.0475 - val_acc: 0.5997\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0155 - acc: 0.6078 - val_loss: 1.0283 - val_acc: 0.5913\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0140 - acc: 0.6073 - val_loss: 1.0145 - val_acc: 0.6002\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0085 - acc: 0.6110 - val_loss: 1.0020 - val_acc: 0.6069\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0025 - acc: 0.6121 - val_loss: 1.0020 - val_acc: 0.6174\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9908 - acc: 0.6174 - val_loss: 0.9908 - val_acc: 0.6222\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9874 - acc: 0.6166 - val_loss: 0.9986 - val_acc: 0.6099\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9761 - acc: 0.6187 - val_loss: 0.9743 - val_acc: 0.6201\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9615 - acc: 0.6258 - val_loss: 0.9616 - val_acc: 0.6272\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9124 - acc: 0.6464 - val_loss: 0.8968 - val_acc: 0.6514\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8875 - acc: 0.6636 - val_loss: 0.8906 - val_acc: 0.6692\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8669 - acc: 0.6799 - val_loss: 0.8843 - val_acc: 0.6853\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8597 - acc: 0.6873 - val_loss: 0.8629 - val_acc: 0.6832\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8495 - acc: 0.6898 - val_loss: 0.8783 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8448 - acc: 0.7004 - val_loss: 0.8722 - val_acc: 0.6890\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8365 - acc: 0.7010 - val_loss: 0.8461 - val_acc: 0.6971\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8356 - acc: 0.6995 - val_loss: 0.8381 - val_acc: 0.7033\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8248 - acc: 0.7107 - val_loss: 0.8574 - val_acc: 0.6944\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8153 - acc: 0.7122 - val_loss: 0.8199 - val_acc: 0.7104\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8030 - acc: 0.7166 - val_loss: 0.7994 - val_acc: 0.7131\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7875 - acc: 0.7231 - val_loss: 0.7784 - val_acc: 0.7280\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7755 - acc: 0.7249 - val_loss: 0.7835 - val_acc: 0.7194\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7637 - acc: 0.7319 - val_loss: 0.7705 - val_acc: 0.7279\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7578 - acc: 0.7339 - val_loss: 0.7611 - val_acc: 0.7358\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7486 - acc: 0.7362 - val_loss: 0.7669 - val_acc: 0.7427\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7478 - acc: 0.7410 - val_loss: 0.7654 - val_acc: 0.7426\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7417 - acc: 0.7447 - val_loss: 0.7550 - val_acc: 0.7473\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7447 - acc: 0.7464 - val_loss: 0.7588 - val_acc: 0.7481\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7360 - acc: 0.7486 - val_loss: 0.7489 - val_acc: 0.7528\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7355 - acc: 0.7548 - val_loss: 0.7385 - val_acc: 0.7556\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7316 - acc: 0.7548 - val_loss: 0.7419 - val_acc: 0.7567\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7253 - acc: 0.7571 - val_loss: 0.7387 - val_acc: 0.7596\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7222 - acc: 0.7588 - val_loss: 0.7440 - val_acc: 0.7624\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 2 ; hid_dim: 16 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.5849 - acc: 0.2550 - val_loss: 1.7757 - val_acc: 0.3204\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6194 - acc: 0.4041 - val_loss: 1.3942 - val_acc: 0.5220\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3013 - acc: 0.5512 - val_loss: 1.2157 - val_acc: 0.5717\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1404 - acc: 0.6064 - val_loss: 1.0772 - val_acc: 0.6212\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0350 - acc: 0.6435 - val_loss: 0.9769 - val_acc: 0.6709\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8538 - acc: 0.7229 - val_loss: 0.7684 - val_acc: 0.7631\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7032 - acc: 0.7753 - val_loss: 0.6497 - val_acc: 0.7850\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6273 - acc: 0.7973 - val_loss: 0.5889 - val_acc: 0.8182\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5476 - acc: 0.8354 - val_loss: 0.5101 - val_acc: 0.8696\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4792 - acc: 0.8691 - val_loss: 0.4564 - val_acc: 0.8850\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4234 - acc: 0.8886 - val_loss: 0.4220 - val_acc: 0.8947\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3827 - acc: 0.9008 - val_loss: 0.3838 - val_acc: 0.9049\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3528 - acc: 0.9070 - val_loss: 0.3577 - val_acc: 0.9117\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3350 - acc: 0.9133 - val_loss: 0.3588 - val_acc: 0.9112\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3183 - acc: 0.9164 - val_loss: 0.3337 - val_acc: 0.9172\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3093 - acc: 0.9188 - val_loss: 0.3371 - val_acc: 0.9183\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3007 - acc: 0.9196 - val_loss: 0.3381 - val_acc: 0.9162\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2928 - acc: 0.9224 - val_loss: 0.3214 - val_acc: 0.9198\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2806 - acc: 0.9239 - val_loss: 0.3412 - val_acc: 0.9145\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2842 - acc: 0.9241 - val_loss: 0.3053 - val_acc: 0.9233\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2719 - acc: 0.9278 - val_loss: 0.3226 - val_acc: 0.9193\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2671 - acc: 0.9280 - val_loss: 0.3030 - val_acc: 0.9232\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2625 - acc: 0.9282 - val_loss: 0.3022 - val_acc: 0.9227\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2554 - acc: 0.9302 - val_loss: 0.3022 - val_acc: 0.9258\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2501 - acc: 0.9321 - val_loss: 0.2862 - val_acc: 0.9278\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2487 - acc: 0.9314 - val_loss: 0.2784 - val_acc: 0.9292\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2375 - acc: 0.9335 - val_loss: 0.2758 - val_acc: 0.9294\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2348 - acc: 0.9361 - val_loss: 0.2891 - val_acc: 0.9250\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2295 - acc: 0.9373 - val_loss: 0.2769 - val_acc: 0.9311\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2228 - acc: 0.9379 - val_loss: 0.2619 - val_acc: 0.9347\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2173 - acc: 0.9399 - val_loss: 0.2624 - val_acc: 0.9331\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2125 - acc: 0.9404 - val_loss: 0.2678 - val_acc: 0.9323\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2077 - acc: 0.9424 - val_loss: 0.2774 - val_acc: 0.9311\n",
      "313/313 [==============================] - 0s 938us/step\n",
      "======== layers: 2 ; hid_dim: 32 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.3714 - acc: 0.5272 - val_loss: 0.9557 - val_acc: 0.7045\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7907 - acc: 0.7878 - val_loss: 0.6340 - val_acc: 0.8394\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5509 - acc: 0.8602 - val_loss: 0.5254 - val_acc: 0.8734\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4564 - acc: 0.8825 - val_loss: 0.4386 - val_acc: 0.8882\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3997 - acc: 0.8940 - val_loss: 0.4140 - val_acc: 0.8972\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3589 - acc: 0.9051 - val_loss: 0.3960 - val_acc: 0.9043\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3352 - acc: 0.9126 - val_loss: 0.3515 - val_acc: 0.9168\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3102 - acc: 0.9187 - val_loss: 0.3475 - val_acc: 0.9172\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2949 - acc: 0.9225 - val_loss: 0.3657 - val_acc: 0.9078\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2713 - acc: 0.9279 - val_loss: 0.3218 - val_acc: 0.9228\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2637 - acc: 0.9301 - val_loss: 0.3014 - val_acc: 0.9266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2562 - acc: 0.9326 - val_loss: 0.3308 - val_acc: 0.9267\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2412 - acc: 0.9365 - val_loss: 0.2981 - val_acc: 0.9287\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2321 - acc: 0.9387 - val_loss: 0.3127 - val_acc: 0.9249\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2293 - acc: 0.9390 - val_loss: 0.2896 - val_acc: 0.9315\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2216 - acc: 0.9411 - val_loss: 0.2761 - val_acc: 0.9358\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2116 - acc: 0.9428 - val_loss: 0.2810 - val_acc: 0.9337\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2059 - acc: 0.9438 - val_loss: 0.2982 - val_acc: 0.9311\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2044 - acc: 0.9455 - val_loss: 0.3065 - val_acc: 0.9329\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 2 ; hid_dim: 64 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 3.4861 - acc: 0.8071 - val_loss: 0.8885 - val_acc: 0.8669\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6363 - acc: 0.8906 - val_loss: 0.5465 - val_acc: 0.8919\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3976 - acc: 0.9128 - val_loss: 0.4278 - val_acc: 0.9137\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2968 - acc: 0.9283 - val_loss: 0.3775 - val_acc: 0.9187\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2420 - acc: 0.9392 - val_loss: 0.3455 - val_acc: 0.9298\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2054 - acc: 0.9454 - val_loss: 0.3096 - val_acc: 0.9309\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1777 - acc: 0.9521 - val_loss: 0.3064 - val_acc: 0.9372\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1665 - acc: 0.9553 - val_loss: 0.2941 - val_acc: 0.9361\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1580 - acc: 0.9563 - val_loss: 0.2981 - val_acc: 0.9425\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1545 - acc: 0.9571 - val_loss: 0.2902 - val_acc: 0.9427\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1352 - acc: 0.9629 - val_loss: 0.2653 - val_acc: 0.9493\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1325 - acc: 0.9635 - val_loss: 0.3290 - val_acc: 0.9377\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1242 - acc: 0.9656 - val_loss: 0.2826 - val_acc: 0.9491\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1260 - acc: 0.9652 - val_loss: 0.2834 - val_acc: 0.9470\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 2 ; hid_dim: 128 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 3.7273 - acc: 0.8396 - val_loss: 0.8906 - val_acc: 0.8974\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6024 - acc: 0.9184 - val_loss: 0.6027 - val_acc: 0.9211\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3625 - acc: 0.9392 - val_loss: 0.4641 - val_acc: 0.9337\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2665 - acc: 0.9493 - val_loss: 0.4327 - val_acc: 0.9371\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2185 - acc: 0.9570 - val_loss: 0.3711 - val_acc: 0.9448\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1715 - acc: 0.9637 - val_loss: 0.3796 - val_acc: 0.9452\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1794 - acc: 0.9634 - val_loss: 0.3774 - val_acc: 0.9462\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1661 - acc: 0.9650 - val_loss: 0.3943 - val_acc: 0.9428\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 2 ; hid_dim: 256 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.0154 - acc: 0.8839 - val_loss: 0.8601 - val_acc: 0.9158\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4793 - acc: 0.9441 - val_loss: 0.5249 - val_acc: 0.9427\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2694 - acc: 0.9612 - val_loss: 0.4486 - val_acc: 0.9508\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2029 - acc: 0.9683 - val_loss: 0.4342 - val_acc: 0.9513\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1621 - acc: 0.9734 - val_loss: 0.4062 - val_acc: 0.9514\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1585 - acc: 0.9737 - val_loss: 0.4167 - val_acc: 0.9569\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1524 - acc: 0.9755 - val_loss: 0.3694 - val_acc: 0.9564\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1296 - acc: 0.9770 - val_loss: 0.4041 - val_acc: 0.9543\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1307 - acc: 0.9773 - val_loss: 0.3277 - val_acc: 0.9611\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1025 - acc: 0.9804 - val_loss: 0.3582 - val_acc: 0.9628\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1009 - acc: 0.9811 - val_loss: 0.3300 - val_acc: 0.9603\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0958 - acc: 0.9820 - val_loss: 0.3593 - val_acc: 0.9586\n",
      "313/313 [==============================] - 0s 970us/step\n",
      "======== layers: 2 ; hid_dim: 512 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.2611 - acc: 0.8957 - val_loss: 0.5452 - val_acc: 0.9419\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3515 - acc: 0.9522 - val_loss: 0.4540 - val_acc: 0.9426\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1966 - acc: 0.9670 - val_loss: 0.3773 - val_acc: 0.9528\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1739 - acc: 0.9703 - val_loss: 0.4419 - val_acc: 0.9477\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1634 - acc: 0.9729 - val_loss: 0.3285 - val_acc: 0.9598\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1398 - acc: 0.9755 - val_loss: 0.4039 - val_acc: 0.9548\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1248 - acc: 0.9778 - val_loss: 0.3108 - val_acc: 0.9586\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1044 - acc: 0.9804 - val_loss: 0.2781 - val_acc: 0.9617\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0926 - acc: 0.9813 - val_loss: 0.2629 - val_acc: 0.9653\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0752 - acc: 0.9841 - val_loss: 0.3338 - val_acc: 0.9614\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0901 - acc: 0.9824 - val_loss: 0.2441 - val_acc: 0.9647\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0713 - acc: 0.9835 - val_loss: 0.2570 - val_acc: 0.9622\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0801 - acc: 0.9828 - val_loss: 0.2416 - val_acc: 0.9643\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0844 - acc: 0.9830 - val_loss: 0.3004 - val_acc: 0.9599\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0860 - acc: 0.9818 - val_loss: 0.2433 - val_acc: 0.9627\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0776 - acc: 0.9830 - val_loss: 0.2637 - val_acc: 0.9652\n",
      "313/313 [==============================] - 0s 999us/step\n",
      "======== layers: 2 ; hid_dim: 1024 ========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 3.4693 - acc: 0.9066 - val_loss: 0.3767 - val_acc: 0.9448\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2437 - acc: 0.9568 - val_loss: 0.3167 - val_acc: 0.9520\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1568 - acc: 0.9703 - val_loss: 0.3096 - val_acc: 0.9581\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1433 - acc: 0.9722 - val_loss: 0.3308 - val_acc: 0.9532\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1265 - acc: 0.9757 - val_loss: 0.3226 - val_acc: 0.9553\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1055 - acc: 0.9793 - val_loss: 0.3080 - val_acc: 0.9580\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1051 - acc: 0.9803 - val_loss: 0.2776 - val_acc: 0.9628\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0943 - acc: 0.9805 - val_loss: 0.2468 - val_acc: 0.9670\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1007 - acc: 0.9793 - val_loss: 0.2944 - val_acc: 0.9609\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1059 - acc: 0.9789 - val_loss: 0.2585 - val_acc: 0.9638\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0826 - acc: 0.9829 - val_loss: 0.2959 - val_acc: 0.9611\n",
      "313/313 [==============================] - 0s 948us/step\n",
      "======== layers: 3 ; hid_dim: 1 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 2.3017 - acc: 0.1130 - val_loss: 2.3019 - val_acc: 0.1060\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3021 - val_acc: 0.1060\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3021 - val_acc: 0.1060\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3021 - val_acc: 0.1060\n",
      "313/313 [==============================] - 0s 988us/step\n",
      "======== layers: 3 ; hid_dim: 2 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 2.3016 - acc: 0.1138 - val_loss: 2.3019 - val_acc: 0.1060\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3021 - val_acc: 0.1060\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3020 - val_acc: 0.1060\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3011 - acc: 0.1140 - val_loss: 2.3021 - val_acc: 0.1060\n",
      "313/313 [==============================] - 0s 967us/step\n",
      "======== layers: 3 ; hid_dim: 4 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.8601 - acc: 0.3220 - val_loss: 1.5430 - val_acc: 0.4080\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.4225 - acc: 0.4494 - val_loss: 1.3091 - val_acc: 0.4737\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2641 - acc: 0.5182 - val_loss: 1.2015 - val_acc: 0.5428\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1795 - acc: 0.5600 - val_loss: 1.1312 - val_acc: 0.5673\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1167 - acc: 0.5884 - val_loss: 1.0780 - val_acc: 0.6067\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0694 - acc: 0.6118 - val_loss: 1.0394 - val_acc: 0.6217\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0411 - acc: 0.6220 - val_loss: 1.0183 - val_acc: 0.6209\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0100 - acc: 0.6304 - val_loss: 0.9721 - val_acc: 0.6514\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9591 - acc: 0.6555 - val_loss: 0.9254 - val_acc: 0.6843\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9093 - acc: 0.6818 - val_loss: 0.8663 - val_acc: 0.7054\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8547 - acc: 0.7137 - val_loss: 0.8342 - val_acc: 0.7519\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7993 - acc: 0.7638 - val_loss: 0.7625 - val_acc: 0.7849\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7492 - acc: 0.7807 - val_loss: 0.7166 - val_acc: 0.7930\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7198 - acc: 0.7873 - val_loss: 0.7046 - val_acc: 0.8021\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7108 - acc: 0.7913 - val_loss: 0.7056 - val_acc: 0.7993\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6983 - acc: 0.7951 - val_loss: 0.7076 - val_acc: 0.8044\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6942 - acc: 0.7962 - val_loss: 0.7036 - val_acc: 0.8042\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6946 - acc: 0.7960 - val_loss: 0.6767 - val_acc: 0.8054\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6875 - acc: 0.7964 - val_loss: 0.6841 - val_acc: 0.8023\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6769 - acc: 0.7989 - val_loss: 0.6718 - val_acc: 0.8006\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6751 - acc: 0.8014 - val_loss: 0.6751 - val_acc: 0.8035\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6720 - acc: 0.8014 - val_loss: 0.6667 - val_acc: 0.8093\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6660 - acc: 0.8026 - val_loss: 0.6691 - val_acc: 0.8042\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6625 - acc: 0.8034 - val_loss: 0.6960 - val_acc: 0.7968\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6563 - acc: 0.8035 - val_loss: 0.6526 - val_acc: 0.8065\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6502 - acc: 0.8050 - val_loss: 0.6475 - val_acc: 0.8091\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6511 - acc: 0.8057 - val_loss: 0.6710 - val_acc: 0.8077\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6460 - acc: 0.8059 - val_loss: 0.6433 - val_acc: 0.8098\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6463 - acc: 0.8050 - val_loss: 0.6460 - val_acc: 0.8089\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6431 - acc: 0.8065 - val_loss: 0.6478 - val_acc: 0.8081\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6384 - acc: 0.8070 - val_loss: 0.6389 - val_acc: 0.8098\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6449 - acc: 0.8063 - val_loss: 0.6479 - val_acc: 0.8057\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6360 - acc: 0.8067 - val_loss: 0.6495 - val_acc: 0.8066\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6382 - acc: 0.8084 - val_loss: 0.6448 - val_acc: 0.8096\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 3 ; hid_dim: 8 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 2.7548 - acc: 0.1131 - val_loss: 2.3008 - val_acc: 0.1072\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2995 - acc: 0.1166 - val_loss: 2.2905 - val_acc: 0.1192\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.1824 - acc: 0.1817 - val_loss: 2.0350 - val_acc: 0.2303\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7445 - acc: 0.3173 - val_loss: 1.5781 - val_acc: 0.3653\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5612 - acc: 0.3698 - val_loss: 1.5138 - val_acc: 0.3980\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 3ms/step - loss: 1.4944 - acc: 0.3974 - val_loss: 1.4581 - val_acc: 0.4249\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.4427 - acc: 0.4269 - val_loss: 1.4248 - val_acc: 0.4421\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.4056 - acc: 0.4379 - val_loss: 1.3721 - val_acc: 0.4501\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3771 - acc: 0.4495 - val_loss: 1.3339 - val_acc: 0.4763\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2357 - acc: 0.5411 - val_loss: 1.1730 - val_acc: 0.5707\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0904 - acc: 0.6225 - val_loss: 1.0148 - val_acc: 0.6808\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9832 - acc: 0.6685 - val_loss: 0.9588 - val_acc: 0.6828\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9459 - acc: 0.6816 - val_loss: 0.9243 - val_acc: 0.6921\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9228 - acc: 0.6862 - val_loss: 0.9093 - val_acc: 0.6883\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9001 - acc: 0.6954 - val_loss: 0.8765 - val_acc: 0.7004\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8789 - acc: 0.7135 - val_loss: 0.8470 - val_acc: 0.7302\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8511 - acc: 0.7369 - val_loss: 0.8218 - val_acc: 0.7536\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8044 - acc: 0.7569 - val_loss: 0.7927 - val_acc: 0.7768\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7735 - acc: 0.7689 - val_loss: 0.7488 - val_acc: 0.7788\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7657 - acc: 0.7719 - val_loss: 0.7442 - val_acc: 0.7787\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7606 - acc: 0.7721 - val_loss: 0.7515 - val_acc: 0.7747\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7511 - acc: 0.7752 - val_loss: 0.7471 - val_acc: 0.7795\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7489 - acc: 0.7740 - val_loss: 0.7603 - val_acc: 0.7763\n",
      "313/313 [==============================] - 0s 984us/step\n",
      "======== layers: 3 ; hid_dim: 16 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 3.0467 - acc: 0.1859 - val_loss: 2.0628 - val_acc: 0.2040\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0310 - acc: 0.2111 - val_loss: 2.0334 - val_acc: 0.2069\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9216 - acc: 0.2571 - val_loss: 1.7713 - val_acc: 0.3351\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5445 - acc: 0.3960 - val_loss: 1.4527 - val_acc: 0.4198\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3455 - acc: 0.4689 - val_loss: 1.2412 - val_acc: 0.5073\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1945 - acc: 0.5340 - val_loss: 1.1047 - val_acc: 0.5661\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0518 - acc: 0.6002 - val_loss: 0.9603 - val_acc: 0.6320\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9068 - acc: 0.6297 - val_loss: 0.8585 - val_acc: 0.6403\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8467 - acc: 0.6647 - val_loss: 0.8134 - val_acc: 0.6861\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7996 - acc: 0.6955 - val_loss: 0.7773 - val_acc: 0.7168\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7523 - acc: 0.7286 - val_loss: 0.7139 - val_acc: 0.7474\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6888 - acc: 0.7598 - val_loss: 0.6705 - val_acc: 0.7797\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6145 - acc: 0.8020 - val_loss: 0.5751 - val_acc: 0.8246\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5525 - acc: 0.8304 - val_loss: 0.5280 - val_acc: 0.8403\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5026 - acc: 0.8492 - val_loss: 0.4921 - val_acc: 0.8559\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4688 - acc: 0.8594 - val_loss: 0.4672 - val_acc: 0.8644\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4467 - acc: 0.8664 - val_loss: 0.4521 - val_acc: 0.8641\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4287 - acc: 0.8715 - val_loss: 0.4427 - val_acc: 0.8739\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4112 - acc: 0.8766 - val_loss: 0.4195 - val_acc: 0.8798\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4002 - acc: 0.8800 - val_loss: 0.4176 - val_acc: 0.8821\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3932 - acc: 0.8819 - val_loss: 0.3998 - val_acc: 0.8828\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3800 - acc: 0.8863 - val_loss: 0.4106 - val_acc: 0.8815\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3699 - acc: 0.8899 - val_loss: 0.4103 - val_acc: 0.8778\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3653 - acc: 0.8904 - val_loss: 0.3850 - val_acc: 0.8878\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3555 - acc: 0.8929 - val_loss: 0.3942 - val_acc: 0.8890\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3451 - acc: 0.8970 - val_loss: 0.3801 - val_acc: 0.8918\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3278 - acc: 0.9021 - val_loss: 0.3553 - val_acc: 0.9006\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3096 - acc: 0.9084 - val_loss: 0.3389 - val_acc: 0.9030\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2986 - acc: 0.9126 - val_loss: 0.3337 - val_acc: 0.9071\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2877 - acc: 0.9161 - val_loss: 0.3241 - val_acc: 0.9088\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2839 - acc: 0.9175 - val_loss: 0.3058 - val_acc: 0.9143\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2731 - acc: 0.9204 - val_loss: 0.3053 - val_acc: 0.9144\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2710 - acc: 0.9216 - val_loss: 0.3000 - val_acc: 0.9146\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2603 - acc: 0.9241 - val_loss: 0.2842 - val_acc: 0.9191\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2569 - acc: 0.9262 - val_loss: 0.2904 - val_acc: 0.9183\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2535 - acc: 0.9268 - val_loss: 0.2991 - val_acc: 0.9157\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2527 - acc: 0.9266 - val_loss: 0.3074 - val_acc: 0.9121\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 3 ; hid_dim: 32 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.5965 - acc: 0.4032 - val_loss: 1.3586 - val_acc: 0.5154\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9632 - acc: 0.6874 - val_loss: 0.6797 - val_acc: 0.7927\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5770 - acc: 0.8153 - val_loss: 0.5252 - val_acc: 0.8291\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4834 - acc: 0.8351 - val_loss: 0.4676 - val_acc: 0.8419\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4450 - acc: 0.8431 - val_loss: 0.4533 - val_acc: 0.8481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4116 - acc: 0.8528 - val_loss: 0.4164 - val_acc: 0.8533\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3915 - acc: 0.8617 - val_loss: 0.4081 - val_acc: 0.8687\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3703 - acc: 0.8835 - val_loss: 0.3755 - val_acc: 0.8913\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3363 - acc: 0.9004 - val_loss: 0.3709 - val_acc: 0.8997\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3089 - acc: 0.9124 - val_loss: 0.3324 - val_acc: 0.9104\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2842 - acc: 0.9199 - val_loss: 0.3221 - val_acc: 0.9144\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2621 - acc: 0.9260 - val_loss: 0.2888 - val_acc: 0.9247\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2490 - acc: 0.9306 - val_loss: 0.2918 - val_acc: 0.9232\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2320 - acc: 0.9355 - val_loss: 0.2861 - val_acc: 0.9266\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2262 - acc: 0.9367 - val_loss: 0.2633 - val_acc: 0.9326\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2131 - acc: 0.9404 - val_loss: 0.2591 - val_acc: 0.9350\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2016 - acc: 0.9446 - val_loss: 0.2473 - val_acc: 0.9377\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1911 - acc: 0.9466 - val_loss: 0.2403 - val_acc: 0.9399\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1846 - acc: 0.9481 - val_loss: 0.2328 - val_acc: 0.9422\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1776 - acc: 0.9486 - val_loss: 0.2279 - val_acc: 0.9429\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1726 - acc: 0.9520 - val_loss: 0.2364 - val_acc: 0.9384\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1635 - acc: 0.9545 - val_loss: 0.2172 - val_acc: 0.9450\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1588 - acc: 0.9555 - val_loss: 0.2121 - val_acc: 0.9474\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1529 - acc: 0.9564 - val_loss: 0.2148 - val_acc: 0.9473\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1476 - acc: 0.9588 - val_loss: 0.2339 - val_acc: 0.9413\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1431 - acc: 0.9590 - val_loss: 0.2185 - val_acc: 0.9455\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 3 ; hid_dim: 64 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2228 - acc: 0.7504 - val_loss: 0.4781 - val_acc: 0.8783\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3870 - acc: 0.8973 - val_loss: 0.3295 - val_acc: 0.9107\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2638 - acc: 0.9256 - val_loss: 0.2609 - val_acc: 0.9280\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2136 - acc: 0.9377 - val_loss: 0.2312 - val_acc: 0.9359\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1754 - acc: 0.9491 - val_loss: 0.2178 - val_acc: 0.9404\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1590 - acc: 0.9521 - val_loss: 0.2195 - val_acc: 0.9438\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1362 - acc: 0.9592 - val_loss: 0.1988 - val_acc: 0.9477\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1252 - acc: 0.9624 - val_loss: 0.1837 - val_acc: 0.9514\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1171 - acc: 0.9655 - val_loss: 0.1962 - val_acc: 0.9492\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1077 - acc: 0.9666 - val_loss: 0.2365 - val_acc: 0.9440\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0984 - acc: 0.9699 - val_loss: 0.1961 - val_acc: 0.9511\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 3 ; hid_dim: 128 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.7654 - acc: 0.8389 - val_loss: 0.4353 - val_acc: 0.9086\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3235 - acc: 0.9246 - val_loss: 0.3430 - val_acc: 0.9200\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2034 - acc: 0.9458 - val_loss: 0.2796 - val_acc: 0.9377\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1458 - acc: 0.9592 - val_loss: 0.2416 - val_acc: 0.9457\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1188 - acc: 0.9657 - val_loss: 0.2126 - val_acc: 0.9497\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1038 - acc: 0.9698 - val_loss: 0.2324 - val_acc: 0.9472\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0922 - acc: 0.9731 - val_loss: 0.2139 - val_acc: 0.9560\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0849 - acc: 0.9755 - val_loss: 0.2062 - val_acc: 0.9562\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0879 - acc: 0.9749 - val_loss: 0.2330 - val_acc: 0.9531\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0846 - acc: 0.9760 - val_loss: 0.2344 - val_acc: 0.9553\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0901 - acc: 0.9757 - val_loss: 0.2192 - val_acc: 0.9568\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 3 ; hid_dim: 256 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 1.9093 - acc: 0.8747 - val_loss: 0.4112 - val_acc: 0.9265\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2493 - acc: 0.9461 - val_loss: 0.2831 - val_acc: 0.9402\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1545 - acc: 0.9610 - val_loss: 0.2609 - val_acc: 0.9487\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1129 - acc: 0.9715 - val_loss: 0.2132 - val_acc: 0.9543\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1040 - acc: 0.9732 - val_loss: 0.2174 - val_acc: 0.9567\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0929 - acc: 0.9754 - val_loss: 0.2476 - val_acc: 0.9541\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1017 - acc: 0.9748 - val_loss: 0.2308 - val_acc: 0.9585\n",
      "313/313 [==============================] - 0s 939us/step\n",
      "======== layers: 3 ; hid_dim: 512 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 1.9767 - acc: 0.8883 - val_loss: 0.3186 - val_acc: 0.9293\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1807 - acc: 0.9546 - val_loss: 0.2653 - val_acc: 0.9431\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1186 - acc: 0.9677 - val_loss: 0.2064 - val_acc: 0.9558\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0999 - acc: 0.9740 - val_loss: 0.2094 - val_acc: 0.9557\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0975 - acc: 0.9740 - val_loss: 0.2576 - val_acc: 0.9540\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0907 - acc: 0.9759 - val_loss: 0.1992 - val_acc: 0.9628\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0693 - acc: 0.9808 - val_loss: 0.1734 - val_acc: 0.9635\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0648 - acc: 0.9823 - val_loss: 0.2144 - val_acc: 0.9617\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0818 - acc: 0.9788 - val_loss: 0.1702 - val_acc: 0.9651\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0660 - acc: 0.9816 - val_loss: 0.1792 - val_acc: 0.9667\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0597 - acc: 0.9842 - val_loss: 0.1615 - val_acc: 0.9667\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0473 - acc: 0.9867 - val_loss: 0.1830 - val_acc: 0.9625\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0620 - acc: 0.9836 - val_loss: 0.1766 - val_acc: 0.9646\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0493 - acc: 0.9867 - val_loss: 0.1769 - val_acc: 0.9672\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "======== layers: 3 ; hid_dim: 1024 ========\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.5109 - acc: 0.8994 - val_loss: 0.2161 - val_acc: 0.9445\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1287 - acc: 0.9625 - val_loss: 0.1883 - val_acc: 0.9565\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0994 - acc: 0.9711 - val_loss: 0.2184 - val_acc: 0.9480\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0901 - acc: 0.9745 - val_loss: 0.1783 - val_acc: 0.9617\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0895 - acc: 0.9755 - val_loss: 0.1749 - val_acc: 0.9581\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0769 - acc: 0.9784 - val_loss: 0.1620 - val_acc: 0.9630\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0677 - acc: 0.9809 - val_loss: 0.1818 - val_acc: 0.9629\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0641 - acc: 0.9821 - val_loss: 0.1687 - val_acc: 0.9630\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0657 - acc: 0.9828 - val_loss: 0.1559 - val_acc: 0.9657\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0656 - acc: 0.9818 - val_loss: 0.1382 - val_acc: 0.9676\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0654 - acc: 0.9833 - val_loss: 0.1355 - val_acc: 0.9708\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0622 - acc: 0.9841 - val_loss: 0.1444 - val_acc: 0.9701\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0423 - acc: 0.9879 - val_loss: 0.1513 - val_acc: 0.9728\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0511 - acc: 0.9867 - val_loss: 0.1687 - val_acc: 0.9694\n",
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "dim_hidden_layres = [2**i for i in range(11)]\n",
    "n_layers = range(1, 4)\n",
    "\n",
    "df_accuracy = pd.DataFrame()\n",
    "\n",
    "for layers in n_layers:\n",
    "    for hid_dim in dim_hidden_layres:\n",
    "        print('========', 'layers:', layers, '; hid_dim:', hid_dim, '========')\n",
    "        model = DenseModel(layers=layers, hid_dim=hid_dim)\n",
    "        model = model.build()\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "        callbacks = [\n",
    "            EarlyStopping(patience=3),\n",
    "            ModelCheckpoint(filepath=os.path.join('models', 'DNN', 'model_{}_{}.h5'.format(layers, hid_dim)), save_best_only=True),\n",
    "        ]\n",
    "        n_param = model.count_params()\n",
    "        model.fit(x=x_train, y=y_train, batch_size=128, epochs=100, callbacks=callbacks, validation_split=0.2)\n",
    "        acc = accuracy_score(y_test, model.predict(x_test).argmax(axis=-1))\n",
    "        \n",
    "        df_accuracy = pd.concat([df_accuracy, pd.DataFrame([[layers, hid_dim, n_param, acc]], columns=['layers', 'hid_dim', 'n_param', 'accuracy'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"11\" halign=\"left\">n_param</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hid_dim</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>16</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>512</th>\n",
       "      <th>1024</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>805</td>\n",
       "      <td>1600</td>\n",
       "      <td>3190</td>\n",
       "      <td>6370</td>\n",
       "      <td>12730</td>\n",
       "      <td>25450</td>\n",
       "      <td>50890</td>\n",
       "      <td>101770</td>\n",
       "      <td>203530</td>\n",
       "      <td>407050</td>\n",
       "      <td>814090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>807</td>\n",
       "      <td>1606</td>\n",
       "      <td>3210</td>\n",
       "      <td>6442</td>\n",
       "      <td>13002</td>\n",
       "      <td>26506</td>\n",
       "      <td>55050</td>\n",
       "      <td>118282</td>\n",
       "      <td>269322</td>\n",
       "      <td>669706</td>\n",
       "      <td>1863690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>809</td>\n",
       "      <td>1612</td>\n",
       "      <td>3230</td>\n",
       "      <td>6514</td>\n",
       "      <td>13274</td>\n",
       "      <td>27562</td>\n",
       "      <td>59210</td>\n",
       "      <td>134794</td>\n",
       "      <td>335114</td>\n",
       "      <td>932362</td>\n",
       "      <td>2913290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_param                                                         \\\n",
       "hid_dim    1     2     4     8      16     32     64      128     256    \n",
       "layers                                                                   \n",
       "1           805  1600  3190  6370  12730  25450  50890  101770  203530   \n",
       "2           807  1606  3210  6442  13002  26506  55050  118282  269322   \n",
       "3           809  1612  3230  6514  13274  27562  59210  134794  335114   \n",
       "\n",
       "                          \n",
       "hid_dim    512      1024  \n",
       "layers                    \n",
       "1        407050   814090  \n",
       "2        669706  1863690  \n",
       "3        932362  2913290  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"11\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hid_dim</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>16</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>512</th>\n",
       "      <th>1024</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.3034</td>\n",
       "      <td>0.8084</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9503</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.9617</td>\n",
       "      <td>0.9687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.6219</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>0.9368</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.9577</td>\n",
       "      <td>0.9661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.3898</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.8490</td>\n",
       "      <td>0.9203</td>\n",
       "      <td>0.9504</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.9659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy                                                          \\\n",
       "hid_dim     1       2       4       8       16      32      64      128    \n",
       "layers                                                                     \n",
       "1         0.1135  0.1135  0.3034  0.8084  0.8856  0.9438  0.9503  0.9521   \n",
       "2         0.1135  0.1136  0.1135  0.6219  0.9037  0.9368  0.9442  0.9465   \n",
       "3         0.1135  0.3898  0.1134  0.8490  0.9203  0.9504  0.9592  0.9619   \n",
       "\n",
       "                                 \n",
       "hid_dim    256     512     1024  \n",
       "layers                           \n",
       "1        0.9583  0.9617  0.9687  \n",
       "2        0.9671  0.9577  0.9661  \n",
       "3        0.9583  0.9687  0.9659  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_accuracy.set_index(['layers', 'hid_dim'])[['n_param']].unstack())\n",
    "display(df_accuracy.set_index(['layers', 'hid_dim'])[['accuracy']].unstack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy.to_csv('dnn_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
